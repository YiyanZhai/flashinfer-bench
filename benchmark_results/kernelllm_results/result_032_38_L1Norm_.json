{
  "device_info": {
    "device_name": "NVIDIA GeForce RTX 4090",
    "device_id": 0,
    "device_str": "cuda:0",
    "compute_capability": [
      8,
      9
    ],
    "total_memory": 25386352640,
    "driver_version": "12.4",
    "backend": "triton"
  },
  "kernel_spec": {
    "description_file": "benchmark/level1/38_L1Norm_.py",
    "generator_file": "generators/kernelllm_generator.py",
    "warmup": 5,
    "iterations": 10,
    "max_diff_limit": 1e-05,
    "report_n": 10,
    "correctness_trials": 1,
    "seed": 42,
    "backend": "triton",
    "use_ncu": false
  },
  "baseline_time": 0.013926400244235993,
  "success_rate": 0.0,
  "avg_speedup": 0.0,
  "max_speedup": 0.0,
  "compilation_success_rate": 0.9,
  "correctness_success_rate": 0.0,
  "generations": [
    {
      "round": 0,
      "compiled": true,
      "correctness": false,
      "max_diff": 5152158.0,
      "avg_diff": 4914.421875,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_abs_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x1 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 32768 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 32768 * x1), None)\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp6 = tmp0 / tmp5\n    tl.store(out_ptr0 + x3, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_abs_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "5152158.000000"
        ],
        "avg_differences": [
          "4914.421875"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 5152158.0,
            "avg_diff": 4914.421875
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 5152158.0,
        "overall_avg_diff": 4914.421875
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 1,
      "compiled": true,
      "correctness": false,
      "max_diff": 5152158.0,
      "avg_diff": 4914.421875,
      "runtime": null,
      "speedup": null,
      "generated_code": "```\nimport torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.constexpr\n    ):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x1 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 32768 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 32768 * x1), None)\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp6 = tmp0 / tmp5\n    tl.store(out_ptr0 + x3, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "5152158.000000"
        ],
        "avg_differences": [
          "4914.421875"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 5152158.0,
            "avg_diff": 4914.421875
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 5152158.0,
        "overall_avg_diff": 4914.421875
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 2,
      "compiled": true,
      "correctness": false,
      "max_diff": 5152158.0,
      "avg_diff": 4914.421875,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_abs_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x1 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 32768 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 32768 * x1), None)\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp6 = tmp0 / tmp5\n    tl.store(out_ptr0 + x3, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_abs_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "5152158.000000"
        ],
        "avg_differences": [
          "4914.421875"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 5152158.0,
            "avg_diff": 4914.421875
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 5152158.0,
        "overall_avg_diff": 4914.421875
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 3,
      "compiled": true,
      "correctness": false,
      "max_diff": 3.504502534866333,
      "avg_diff": 0.14981654286384583,
      "runtime": null,
      "speedup": null,
      "generated_code": "```\nimport torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_abs_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x2 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp6 = tl.load(in_ptr0 + (32768 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (49152 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp12 = tl.load(in_ptr0 + (65536 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (81920 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp18 = tl.load(in_ptr0 + (98304 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp7 = tl_math.abs(tmp6)\n    tmp8 = tmp5 + tmp7\n    tmp10 = tl_math.abs(tmp9)\n    tmp11 = tmp8 + tmp10\n    tmp13 = tl_math.abs(tmp12)\n    tmp14 = tmp11 + tmp13\n    tmp16 = tl_math.abs(tmp15)\n    tmp17 = tmp14 + tmp16\n    tmp19 = tl_math.abs(tmp18)\n    tmp20 = tmp17 + tmp19\n    tmp21 = tmp0 / tmp20\n    tl.store(out_ptr0 + x3, tmp21, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_abs_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "3.504503"
        ],
        "avg_differences": [
          "0.149817"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 3.504502534866333,
            "avg_diff": 0.14981654286384583
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 3.504502534866333,
        "overall_avg_diff": 0.14981654286384583
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 4,
      "compiled": true,
      "correctness": false,
      "max_diff": 5152158.0,
      "avg_diff": 4914.421875,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.constexpr\n    ):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x1 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 32768 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 32768 * x1), None)\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp6 = tmp0 / tmp5\n    tl.store(out_ptr0 + x3, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "5152158.000000"
        ],
        "avg_differences": [
          "4914.421875"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 5152158.0,
            "avg_diff": 4914.421875
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 5152158.0,
        "overall_avg_diff": 4914.421875
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 5,
      "compiled": true,
      "correctness": false,
      "max_diff": 3.504502534866333,
      "avg_diff": 0.14981654286384583,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.constexpr\n    ):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x2 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp6 = tl.load(in_ptr0 + (32768 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (49152 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp12 = tl.load(in_ptr0 + (65536 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (81920 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp18 = tl.load(in_ptr0 + (98304 + x0 + 16384 * (x2 // 16)), None,\n        eviction_policy='evict_last')\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp7 = tl_math.abs(tmp6)\n    tmp8 = tmp5 + tmp7\n    tmp10 = tl_math.abs(tmp9)\n    tmp11 = tmp8 + tmp10\n    tmp13 = tl_math.abs(tmp12)\n    tmp14 = tmp11 + tmp13\n    tmp16 = tl_math.abs(tmp15)\n    tmp17 = tmp14 + tmp16\n    tmp19 = tl_math.abs(tmp18)\n    tmp20 = tmp17 + tmp19\n    tmp21 = tmp0 / tmp20\n    tl.store(out_ptr0 + x3, tmp21, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "3.504503"
        ],
        "avg_differences": [
          "0.149817"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 3.504502534866333,
            "avg_diff": 0.14981654286384583
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 3.504502534866333,
        "overall_avg_diff": 0.14981654286384583
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 6,
      "compiled": true,
      "correctness": false,
      "max_diff": 679.590087890625,
      "avg_diff": 1.1339964866638184,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_abs_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.constexpr\n    ):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 16384\n    x1 = xindex // 16384\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (x0 + 16384 * (x1 // 1024) + 262144 * (x1 % \n        1024)), None)\n    tmp2 = tl.load(in_ptr0 + (16384 * (x1 // 1024) + 262144 * (x1 % 1024) +\n        x0 % 1024), None)\n    tmp4 = tl.load(in_ptr0 + (32768 * (x1 // 1024) + 262144 * (x1 % 1024) +\n        x0 % 1024), None)\n    tmp6 = tl.load(in_ptr0 + (49152 * (x1 // 1024) + 262144 * (x1 % 1024) +\n        x0 % 1024), None)\n    tmp1 = tl_math.abs(tmp0)\n    tmp3 = tl_math.abs(tmp2)\n    tmp5 = tl_math.abs(tmp4)\n    tmp7 = tl_math.abs(tmp6)\n    tmp8 = tmp1 + tmp3\n    tmp9 = tmp8 + tmp5\n    tmp10 = tmp9 + tmp7\n    tl.store(out_ptr0 + x2, tmp10, None)\n\n\n@triton.jit\ndef triton_poi_fused_div_1(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 1024\n    x2 = xindex // 262144\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr1 + (x0 + 1024 * x2), None, eviction_policy=\n        'evict_last')\n    tmp2 = tmp0 / tmp1\n    tl.store(out_ptr0 + x3, tmp2, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 1, 1024), (1024, 16384, 1), torch.\n            float32)\n        get_raw_stream(0)\n        triton_poi_fused_abs_sum_0[grid(16384)](arg0_1, buf0, 16384, XBLOCK\n            =256, num_warps=4, num_stages=1)\n        buf1 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        triton_poi_fused_div_1[grid(262144)](arg0_1, buf0, buf1, 262144,\n            XBLOCK=1024, num_warps=4, num_stages=1)\n        del arg0_1\n        del buf0\n    return buf1,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "679.590088"
        ],
        "avg_differences": [
          "1.133996"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 679.590087890625,
            "avg_diff": 1.1339964866638184
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 679.590087890625,
        "overall_avg_diff": 1.1339964866638184
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 7,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.559181272983551,
      "avg_diff": 0.07746922969818115,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_abs_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 1024\n    x2 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 16384 * x2), None, eviction_policy=\n        'evict_last')\n    tmp3 = tl.load(in_ptr0 + (1024 + x0 + 16384 * x2), None, eviction_policy\n        ='evict_last')\n    tmp6 = tl.load(in_ptr0 + (2048 + x0 + 16384 * x2), None, eviction_policy\n        ='evict_last')\n    tmp9 = tl.load(in_ptr0 + (3072 + x0 + 16384 * x2), None, eviction_policy\n        ='evict_last')\n    tmp12 = tl.load(in_ptr0 + (4096 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (5120 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp18 = tl.load(in_ptr0 + (6144 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp21 = tl.load(in_ptr0 + (7168 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp24 = tl.load(in_ptr0 + (8192 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp27 = tl.load(in_ptr0 + (9216 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp30 = tl.load(in_ptr0 + (10240 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp33 = tl.load(in_ptr0 + (11264 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp36 = tl.load(in_ptr0 + (12288 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp7 = tl_math.abs(tmp6)\n    tmp8 = tmp5 + tmp7\n    tmp10 = tl_math.abs(tmp9)\n    tmp11 = tmp8 + tmp10\n    tmp13 = tl_math.abs(tmp12)\n    tmp14 = tmp11 + tmp13\n    tmp16 = tl_math.abs(tmp15)\n    tmp17 = tmp14 + tmp16\n    tmp19 = tl_math.abs(tmp18)\n    tmp20 = tmp17 + tmp19\n    tmp22 = tl_math.abs(tmp21)\n    tmp23 = tmp20 + tmp22\n    tmp25 = tl_math.abs(tmp24)\n    tmp26 = tmp23 + tmp25\n    tmp28 = tl_math.abs(tmp27)\n    tmp29 = tmp26 + tmp28\n    tmp31 = tl_math.abs(tmp30)\n    tmp32 = tmp29 + tmp31\n    tmp34 = tl_math.abs(tmp33)\n    tmp35 = tmp32 + tmp34\n    tmp37 = tl_math.abs(tmp36)\n    tmp38 = tmp35 + tmp37\n    tmp39 = tmp0 / tmp38\n    tl.store(out_ptr0 + x3, tmp39, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_abs_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.559181"
        ],
        "avg_differences": [
          "0.077469"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.559181272983551,
            "avg_diff": 0.07746922969818115
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.559181272983551,
        "overall_avg_diff": 0.07746922969818115
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 8,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.constexpr\n    ):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x1 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 165888 * x1), None, eviction_policy=\n        'evict_last')\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 165888 * x1), None,\n        eviction_policy='evict_last')\n    tmp6 = tl.load(in_ptr0 + (32768 + x0 + 165888 * x1), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (49152 + x0 + 165888 * x1), None,\n        eviction_policy='evict_last')\n    tmp12 = tl.load(in_ptr0 + (65536 + x0 + 165888 * x1), None,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (81920 + x0 + 165888 * x1), None,\n        eviction_policy='evict_last')\n    tmp18 = tl.load(in_ptr0 + (98304 + x0 + 165888 * x1), None,\n        eviction_policy='evict_last')\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp7 = tl_math.abs(tmp6)\n    tmp8 = tmp5 + tmp7\n    tmp10 = tl_math.abs(tmp9)\n    tmp11 = tmp8 + tmp10\n    tmp13 = tl_math.abs(tmp12)\n    tmp14 = tmp11 + tmp13\n    tmp16 = tl_math.abs(tmp15)\n    tmp17 = tmp14 + tmp16\n    tmp19 = tl_math.abs(tmp18)\n    tmp20 = tmp17 + tmp19\n    tmp21 = tmp0 / tmp20\n    tl.store(out_ptr0 + x3, tmp21, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "runtime_error_name": "RuntimeError"
      },
      "compilation_error": null,
      "runtime_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "generation_error": null
    },
    {
      "round": 9,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import math as tl_math\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_abs_div_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x1 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 16384 * (x1 // 16)), None,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 16384 * (x1 // 16)), None,\n        eviction_policy='evict_last')\n    tmp6 = tl.load(in_ptr0 + (32768 + x0 + 16384 * (x1 // 16)), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (49152 + x0 + 16384 * (x1 // 16)), None,\n        eviction_policy='evict_last')\n    tmp12 = tl.load(in_ptr0 + (65536 + x0 + 16384 * (x1 // 16)), None,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (81920 + x0 + 16384 * (x1 // 16)), None,\n        eviction_policy='evict_last')\n    tmp18 = tl.load(in_ptr0 + (98304 + x0 + 16384 * (x1 // 16)), None,\n        eviction_policy='evict_last')\n    tmp2 = tl_math.abs(tmp1)\n    tmp4 = tl_math.abs(tmp3)\n    tmp5 = tmp2 + tmp4\n    tmp7 = tl_math.abs(tmp6)\n    tmp8 = tmp5 + tmp7\n    tmp10 = tl_math.abs(tmp9)\n    tmp11 = tmp8 + tmp10\n    tmp13 = tl_math.abs(tmp12)\n    tmp14 = tmp11 + tmp13\n    tmp16 = tl_math.abs(tmp15)\n    tmp17 = tmp14 + tmp16\n    tmp19 = tl_math.abs(tmp18)\n    tmp20 = tmp17 + tmp19\n    tmp21 = tmp0 / tmp20\n    tl.store(out_ptr0 + x3, tmp21, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_abs_div_sum_0[grid(262144)](arg0_1, buf0, 262144,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L1 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L1 normalization layer.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    }
  ]
}