{
  "device_info": {
    "device_name": "NVIDIA GeForce RTX 4090",
    "device_id": 0,
    "device_str": "cuda:0",
    "compute_capability": [
      8,
      9
    ],
    "total_memory": 25386352640,
    "driver_version": "12.4",
    "backend": "triton"
  },
  "kernel_spec": {
    "description_file": "benchmark/level1/97_CosineSimilarityLoss.py",
    "generator_file": "generators/kernelllm_generator.py",
    "warmup": 5,
    "iterations": 10,
    "max_diff_limit": 1e-05,
    "report_n": 10,
    "correctness_trials": 1,
    "seed": 42,
    "backend": "triton",
    "use_ncu": false
  },
  "baseline_time": 0.04403199851512909,
  "success_rate": 0.0,
  "avg_speedup": 0.0,
  "max_speedup": 0.0,
  "compilation_success_rate": 1.0,
  "correctness_success_rate": 0.0,
  "generations": [
    {
      "round": 0,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.00023674964904785156,
      "avg_diff": 0.00023674964904785156,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0(in_out_ptr0,\n    in_ptr0, in_ptr1, xnumel, rnumel, XBLOCK: tl.constexpr):\n    RBLOCK: tl.constexpr = 128\n    xoffset = tl.program_id(0) * XBLOCK\n    xoffset + tl.arange(0, XBLOCK)[:, None]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r0 = rindex\n    tmp0 = tl.load(in_ptr0 + r0, None)\n    tmp5 = tl.load(in_ptr1 + r0, None)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.sum(tmp2, 1)[:, None]\n    tmp6 = tmp5 * tmp5\n    tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])\n    tmp9 = tl.sum(tmp7, 1)[:, None]\n    tmp10 = libdevice.sqrt(tmp4)\n    tmp11 = 1e-08\n    tmp12 = triton_helpers.maximum(tmp10, tmp11)\n    tmp13 = tmp0 / tmp12\n    tmp14 = libdevice.sqrt(tmp9)\n    tmp15 = triton_helpers.maximum(tmp14, tmp11)\n    tmp16 = tmp5 / tmp15\n    tmp17 = tmp13 * tmp16\n    tmp18 = tl.broadcast_to(tmp17, [XBLOCK, RBLOCK])\n    tmp20 = tl.sum(tmp18, 1)[:, None]\n    tmp21 = 128.0\n    tmp22 = tmp20 / tmp21\n    tmp23 = 1.0\n    tmp24 = tmp23 - tmp22\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + tl.full([XBLOCK, 1], 0, tl.int32), tmp24, None)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((), (), torch.float32)\n        buf3 = buf0\n        del buf0\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0[grid(1)\n            ](buf3, arg1_1, arg0_1, 1, 128, XBLOCK=1, num_warps=2, num_stages=1\n            )\n        del arg0_1\n        del arg1_1\n    return buf3,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.000237"
        ],
        "avg_differences": [
          "0.000237"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.00023674964904785156,
            "avg_diff": 0.00023674964904785156
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.00023674964904785156,
        "overall_avg_diff": 0.00023674964904785156
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 1,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0(in_out_ptr0\n    , in_ptr0, in_ptr1, xnumel, rnumel, XBLOCK: tl.constexpr):\n    RBLOCK: tl.constexpr = 128\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    xmask = xindex < xnumel\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r1 = rindex\n    x0 = xindex\n    tmp0 = tl.load(in_ptr0 + (r1 + 128 * x0), xmask, other=0.0)\n    tmp5 = tl.load(in_ptr1 + (r1 + 128 * x0), xmask, other=0.0)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.where(xmask, tmp2, 0)\n    tmp6 = tmp5 * tmp5\n    tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])\n    tmp9 = tl.where(xmask, tmp7, 0)\n    tmp10 = tmp4 + tmp9\n    tmp11 = libdevice.sqrt(tmp10)\n    tmp12 = 1e-08\n    tmp13 = triton_helpers.maximum(tmp11, tmp12)\n    tmp14 = tmp0 / tmp13\n    tmp15 = tmp5 / tmp13\n    tmp16 = tmp14 * tmp15\n    tmp17 = tl.broadcast_to(tmp16, [XBLOCK, RBLOCK])\n    tmp19 = tl.where(xmask, tmp17, 0)\n    tmp20 = tl.sum(tmp19, 1)[:, None]\n    tmp21 = 1.0\n    tmp22 = tmp21 - tmp20\n    tmp23 = 128.0\n    tmp24 = tmp22 / tmp23\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + x0, tmp24, xmask)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((128,), (1,), torch.float32)\n        buf1 = buf0\n        del buf0\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0[grid(128)\n            ](buf1, arg1_1, arg0_1, 128, 4096, XBLOCK=8, num_warps=128,\n            num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf1,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "Triton Error [CUDA]: invalid argument",
            "error_type": "RuntimeError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 2,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.00019222497940063477,
      "avg_diff": 0.00019222497940063477,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0(in_out_ptr0,\n    in_ptr0, in_ptr1, xnumel, rnumel):\n    XBLOCK: tl.constexpr = 1\n    RBLOCK: tl.constexpr = 4096\n    xoffset = tl.program_id(0) * XBLOCK\n    tl.full([1], xoffset, tl.int32)\n    tl.full([RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[:]\n    tl.full([RBLOCK], True, tl.int1)\n    r0 = rindex\n    tmp0 = tl.load(in_ptr0 + r0, None)\n    tmp1 = tl.load(in_ptr1 + r0, None)\n    tmp2 = tmp0 * tmp0\n    tmp3 = tl.broadcast_to(tmp2, [RBLOCK])\n    tmp5 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))\n    tmp6 = tmp1 * tmp1\n    tmp7 = tl.broadcast_to(tmp6, [RBLOCK])\n    tmp9 = triton_helpers.promote_to_tensor(tl.sum(tmp7, 0))\n    tmp10 = libdevice.sqrt(tmp5)\n    tmp11 = 1e-08\n    tmp12 = triton_helpers.maximum(tmp10, tmp11)\n    tmp13 = tmp0 / tmp12\n    tmp14 = libdevice.sqrt(tmp9)\n    tmp15 = triton_helpers.maximum(tmp14, tmp11)\n    tmp16 = tmp1 / tmp15\n    tmp17 = tmp13 * tmp16\n    tmp18 = tl.broadcast_to(tmp17, [RBLOCK])\n    tmp20 = triton_helpers.promote_to_tensor(tl.sum(tmp18, 0))\n    tmp21 = 4096.0\n    tmp22 = tmp20 / tmp21\n    tmp23 = 1.0\n    tmp24 = tmp23 - tmp22\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + tl.full([1], 0, tl.int32), tmp24, None)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((), (), torch.float32)\n        buf3 = buf0\n        del buf0\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0[grid(1)\n            ](buf3, arg1_1, arg0_1, 1, 4096, num_warps=8, num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf3,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.000192"
        ],
        "avg_differences": [
          "0.000192"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.00019222497940063477,
            "avg_diff": 0.00019222497940063477
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.00019222497940063477,
        "overall_avg_diff": 0.00019222497940063477
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 3,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.00019222497940063477,
      "avg_diff": 0.00019222497940063477,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mean_mul_rsub_sum_0(\n    in_out_ptr1, in_ptr0, in_ptr1, xnumel, rnumel):\n    XBLOCK: tl.constexpr = 1\n    RBLOCK: tl.constexpr = 4096\n    xoffset = tl.program_id(0) * XBLOCK\n    tl.full([1], xoffset, tl.int32)\n    tl.full([RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[:]\n    tl.full([RBLOCK], True, tl.int1)\n    r0 = rindex\n    tmp0 = tl.load(in_ptr0 + r0, None)\n    tmp6 = tl.load(in_ptr1 + r0, None)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [RBLOCK])\n    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp2, 0))\n    tmp5 = libdevice.sqrt(tmp4)\n    tmp7 = tmp6 * tmp6\n    tmp8 = tl.broadcast_to(tmp7, [RBLOCK])\n    tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp8, 0))\n    tmp11 = libdevice.sqrt(tmp10)\n    tmp12 = 1e-08\n    tmp13 = triton_helpers.maximum(tmp5, tmp12)\n    tmp14 = tmp0 / tmp13\n    tmp15 = triton_helpers.maximum(tmp11, tmp12)\n    tmp16 = tmp6 / tmp15\n    tmp17 = tmp14 * tmp16\n    tmp18 = tl.broadcast_to(tmp17, [RBLOCK])\n    tmp20 = triton_helpers.promote_to_tensor(tl.sum(tmp18, 0))\n    tmp21 = 4096.0\n    tmp22 = tmp20 / tmp21\n    tmp23 = 1.0\n    tmp24 = tmp23 - tmp22\n    tl.debug_barrier()\n    tl.store(in_out_ptr1 + tl.full([1], 0, tl.int32), tmp24, None)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf2 = empty_strided_cuda((), (), torch.float32)\n        buf3 = buf2\n        del buf2\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mean_mul_rsub_sum_0[\n            grid(1)](buf3, arg1_1, arg0_1, 1, 4096, num_warps=8, num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf3,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.000192"
        ],
        "avg_differences": [
          "0.000192"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.00019222497940063477,
            "avg_diff": 0.00019222497940063477
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.00019222497940063477,
        "overall_avg_diff": 0.00019222497940063477
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 4,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.021643638610839844,
      "avg_diff": 0.021643638610839844,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0(in_out_ptr0,\n    in_ptr0, in_ptr1, xnumel, rnumel):\n    XBLOCK: tl.constexpr = 1\n    RBLOCK: tl.constexpr = 4096\n    xoffset = tl.program_id(0) * XBLOCK\n    tl.full([1], xoffset, tl.int32)\n    tl.full([RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[:]\n    tl.full([RBLOCK], True, tl.int1)\n    r0 = rindex\n    tmp0 = tl.load(in_ptr0 + r0, None)\n    tmp6 = tl.load(in_ptr1 + r0, None)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [RBLOCK])\n    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp2, 0))\n    tmp5 = libdevice.sqrt(tmp4)\n    tmp7 = tmp6 * tmp6\n    tmp8 = tl.broadcast_to(tmp7, [RBLOCK])\n    tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp8, 0))\n    tmp11 = libdevice.sqrt(tmp10)\n    tmp12 = 1e-08\n    tmp13 = triton_helpers.maximum(tmp5, tmp12)\n    tmp14 = tmp0 / tmp13\n    tmp15 = triton_helpers.maximum(tmp11, tmp12)\n    tmp16 = tmp6 / tmp15\n    tmp17 = tmp14 * tmp16\n    tmp18 = tl.broadcast_to(tmp17, [RBLOCK])\n    tmp20 = triton_helpers.promote_to_tensor(tl.sum(tmp18, 0))\n    tmp21 = 1.0\n    tmp22 = tmp21 - tmp20\n    tmp23 = tmp22 / tmp21\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + tl.full([1], 0, tl.int32), tmp23, None)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((), (), torch.float32)\n        buf2 = buf0\n        del buf0\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0[grid(1)\n            ](buf2, arg1_1, arg0_1, 1, 4096, num_warps=8, num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf2,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.021644"
        ],
        "avg_differences": [
          "0.021644"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.021643638610839844,
            "avg_diff": 0.021643638610839844
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.021643638610839844,
        "overall_avg_diff": 0.021643638610839844
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 5,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.00019222497940063477,
      "avg_diff": 0.00019222497940063477,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0(in_out_ptr0\n    , in_ptr0, in_ptr1, xnumel, rnumel):\n    XBLOCK: tl.constexpr = 1\n    RBLOCK: tl.constexpr = 4096\n    xoffset = tl.program_id(0) * XBLOCK\n    tl.full([1], xoffset, tl.int32)\n    tl.full([RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[:]\n    tl.full([RBLOCK], True, tl.int1)\n    r0 = rindex\n    tmp0 = tl.load(in_ptr0 + r0, None)\n    tmp1 = tl.load(in_ptr1 + r0, None)\n    tmp2 = tmp0 * tmp0\n    tmp3 = tl.broadcast_to(tmp2, [RBLOCK])\n    tmp5 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))\n    tmp6 = tmp1 * tmp1\n    tmp7 = tl.broadcast_to(tmp6, [RBLOCK])\n    tmp9 = triton_helpers.promote_to_tensor(tl.sum(tmp7, 0))\n    tmp10 = libdevice.sqrt(tmp5)\n    tmp11 = 1e-08\n    tmp12 = triton_helpers.maximum(tmp10, tmp11)\n    tmp13 = tmp0 / tmp12\n    tmp14 = libdevice.sqrt(tmp9)\n    tmp15 = triton_helpers.maximum(tmp14, tmp11)\n    tmp16 = tmp1 / tmp15\n    tmp17 = tmp13 * tmp16\n    tmp18 = tl.broadcast_to(tmp17, [RBLOCK])\n    tmp20 = triton_helpers.promote_to_tensor(tl.sum(tmp18, 0))\n    tmp21 = 4096.0\n    tmp22 = tmp20 / tmp21\n    tmp23 = 1.0\n    tmp24 = tmp23 - tmp22\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + tl.full([1], 0, tl.int32), tmp24, None)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((), (), torch.float32)\n        buf3 = buf0\n        del buf0\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0[grid(1)\n            ](buf3, arg1_1, arg0_1, 1, 4096, num_warps=8, num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf3,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.000192"
        ],
        "avg_differences": [
          "0.000192"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.00019222497940063477,
            "avg_diff": 0.00019222497940063477
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.00019222497940063477,
        "overall_avg_diff": 0.00019222497940063477
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 6,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.021643638610839844,
      "avg_diff": 0.021643638610839844,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0(in_out_ptr0,\n    in_ptr0, in_ptr1, xnumel, rnumel):\n    XBLOCK: tl.constexpr = 1\n    RBLOCK: tl.constexpr = 4096\n    xoffset = tl.program_id(0) * XBLOCK\n    tl.full([1], xoffset, tl.int32)\n    tl.full([RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[:]\n    tl.full([RBLOCK], True, tl.int1)\n    r0 = rindex\n    tmp0 = tl.load(in_ptr0 + r0, None)\n    tmp6 = tl.load(in_ptr1 + r0, None)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [RBLOCK])\n    tmp4 = triton_helpers.promote_to_tensor(tl.sum(tmp2, 0))\n    tmp5 = libdevice.sqrt(tmp4)\n    tmp7 = tmp6 * tmp6\n    tmp8 = tl.broadcast_to(tmp7, [RBLOCK])\n    tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp8, 0))\n    tmp11 = libdevice.sqrt(tmp10)\n    tmp12 = 1e-08\n    tmp13 = triton_helpers.maximum(tmp5, tmp12)\n    tmp14 = tmp0 / tmp13\n    tmp15 = triton_helpers.maximum(tmp11, tmp12)\n    tmp16 = tmp6 / tmp15\n    tmp17 = tmp14 * tmp16\n    tmp18 = tl.broadcast_to(tmp17, [RBLOCK])\n    tmp20 = triton_helpers.promote_to_tensor(tl.sum(tmp18, 0))\n    tmp21 = 1.0\n    tmp22 = tmp21 - tmp20\n    tmp23 = tmp22 / tmp21\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + tl.full([1], 0, tl.int32), tmp23, None)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((), (), torch.float32)\n        buf2 = buf0\n        del buf0\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0[grid(1)\n            ](buf2, arg1_1, arg0_1, 1, 4096, num_warps=8, num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf2,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.021644"
        ],
        "avg_differences": [
          "0.021644"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.021643638610839844,
            "avg_diff": 0.021643638610839844
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.021643638610839844,
        "overall_avg_diff": 0.021643638610839844
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 7,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0(in_out_ptr0\n    , in_ptr0, in_ptr1, xnumel, rnumel, XBLOCK: tl.constexpr):\n    RBLOCK: tl.constexpr = 128\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    xmask = xindex < xnumel\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r1 = rindex\n    x0 = xindex\n    tmp0 = tl.load(in_ptr0 + (r1 + 128 * x0), xmask, other=0.0)\n    tmp6 = tl.load(in_ptr1 + (r1 + 128 * x0), xmask, other=0.0)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.where(xmask, tmp2, 0)\n    tmp5 = tl.sum(tmp4, 1)[:, None]\n    tmp7 = tmp6 * tmp6\n    tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])\n    tmp10 = tl.where(xmask, tmp8, 0)\n    tmp11 = tl.sum(tmp10, 1)[:, None]\n    tmp12 = libdevice.sqrt(tmp5)\n    tmp13 = 1e-08\n    tmp14 = triton_helpers.maximum(tmp12, tmp13)\n    tmp15 = tmp0 / tmp14\n    tmp16 = libdevice.sqrt(tmp11)\n    tmp17 = triton_helpers.maximum(tmp16, tmp13)\n    tmp18 = tmp6 / tmp17\n    tmp19 = tmp15 * tmp18\n    tmp20 = tl.broadcast_to(tmp19, [XBLOCK, RBLOCK])\n    tmp22 = tl.where(xmask, tmp20, 0)\n    tmp23 = tl.sum(tmp22, 1)[:, None]\n    tmp24 = 1.0\n    tmp25 = tmp24 - tmp23\n    tmp26 = tmp25 / tmp24\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + x0, tmp26, xmask)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((128, 1), (1, 128), torch.float32)\n        buf2 = reinterpret_tensor(buf0, (128,), (1,), 0)\n        del buf0\n        buf3 = buf2\n        del buf2\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0[grid(128)\n            ](buf3, arg1_1, arg0_1, 128, 4096, XBLOCK=1, num_warps=2,\n            num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf3,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "name 'reinterpret_tensor' is not defined",
            "error_type": "NameError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 8,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.00023674964904785156,
      "avg_diff": 0.00023674964904785156,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mean_mul_rsub_sum_0(\n    in_out_ptr0, in_ptr0, in_ptr1, xnumel, rnumel, XBLOCK: tl.constexpr):\n    RBLOCK: tl.constexpr = 128\n    xoffset = tl.program_id(0) * XBLOCK\n    xoffset + tl.arange(0, XBLOCK)[:, None]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r0 = rindex\n    tmp0 = tl.load(in_ptr0 + r0, None)\n    tmp1 = tl.load(in_ptr1 + r0, None)\n    tmp2 = tmp0 * tmp1\n    tmp3 = tmp0 * tmp0\n    tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])\n    tmp6 = tl.sum(tmp4, 1)[:, None]\n    tmp7 = tmp1 * tmp1\n    tmp8 = tl.broadcast_to(tmp7, [XBLOCK, RBLOCK])\n    tmp10 = tl.sum(tmp8, 1)[:, None]\n    tmp11 = libdevice.sqrt(tmp6)\n    tmp12 = libdevice.sqrt(tmp10)\n    tmp13 = 1e-08\n    tmp14 = triton_helpers.maximum(tmp11, tmp13)\n    tmp15 = triton_helpers.maximum(tmp12, tmp13)\n    tmp16 = tmp0 / tmp14\n    tmp17 = tmp1 / tmp15\n    tmp18 = tmp16 * tmp17\n    tmp19 = tl.broadcast_to(tmp18, [XBLOCK, RBLOCK])\n    tmp21 = tl.sum(tmp19, 1)[:, None]\n    tmp22 = 128.0\n    tmp23 = tmp21 / tmp22\n    tmp24 = 1.0\n    tmp25 = tmp24 - tmp23\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + tl.full([XBLOCK, 1], 0, tl.int32), tmp25, None)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf2 = empty_strided_cuda((), (), torch.float32)\n        buf3 = buf2\n        del buf2\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mean_mul_rsub_sum_0[\n            grid(1)](buf3, arg1_1, arg0_1, 1, 128, XBLOCK=1, num_warps=2,\n            num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf3,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.000237"
        ],
        "avg_differences": [
          "0.000237"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.00023674964904785156,
            "avg_diff": 0.00023674964904785156
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.00023674964904785156,
        "overall_avg_diff": 0.00023674964904785156
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 9,
      "compiled": true,
      "correctness": false,
      "max_diff": 0.00022411346435546875,
      "avg_diff": 0.00022411346435546875,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0(in_out_ptr0,\n    in_ptr0, in_ptr1, xnumel, rnumel):\n    XBLOCK: tl.constexpr = 1\n    RBLOCK: tl.constexpr = 512\n    xoffset = tl.program_id(0) * XBLOCK\n    tl.full([1], xoffset, tl.int32)\n    tl.full([RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[:]\n    tl.full([RBLOCK], True, tl.int1)\n    r0 = rindex\n    tmp0 = tl.load(in_ptr0 + r0, None)\n    tmp1 = tl.load(in_ptr1 + r0, None)\n    tmp2 = tmp0 * tmp0\n    tmp3 = tl.broadcast_to(tmp2, [RBLOCK])\n    tmp5 = triton_helpers.promote_to_tensor(tl.sum(tmp3, 0))\n    tmp6 = tmp1 * tmp1\n    tmp7 = tl.broadcast_to(tmp6, [RBLOCK])\n    tmp9 = triton_helpers.promote_to_tensor(tl.sum(tmp7, 0))\n    tmp10 = libdevice.sqrt(tmp5)\n    tmp11 = 1e-08\n    tmp12 = triton_helpers.maximum(tmp10, tmp11)\n    tmp13 = tmp0 / tmp12\n    tmp14 = libdevice.sqrt(tmp9)\n    tmp15 = triton_helpers.maximum(tmp14, tmp11)\n    tmp16 = tmp1 / tmp15\n    tmp17 = tmp13 * tmp16\n    tmp18 = tl.broadcast_to(tmp17, [RBLOCK])\n    tmp20 = triton_helpers.promote_to_tensor(tl.sum(tmp18, 0))\n    tmp21 = 512.0\n    tmp22 = tmp20 / tmp21\n    tmp23 = 1.0\n    tmp24 = tmp23 - tmp22\n    tl.debug_barrier()\n    tl.store(in_out_ptr0 + tl.full([1], 0, tl.int32), tmp24, None)\n\n\ndef call(args):\n    arg0_1, arg1_1 = args\n    args.clear()\n    assert_size_stride(arg0_1, (128, 4096), (4096, 1))\n    assert_size_stride(arg1_1, (128, 4096), (4096, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((), (), torch.float32)\n        buf3 = buf0\n        del buf0\n        get_raw_stream(0)\n        triton_per_fused_clamp_min_div_linalg_vector_norm_mul_rsub_sum_0[grid(1)\n            ](buf3, arg1_1, arg0_1, 1, 512, num_warps=4, num_stages=1)\n        del arg0_1\n        del arg1_1\n    return buf3,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that computes Cosine Similarity Loss for comparing vectors.\n\n    Parameters:\n        None\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0, input_1):\n        arg0_1 = input_0\n        arg1_1 = input_1\n        output = call([arg0_1, arg1_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.000224"
        ],
        "avg_differences": [
          "0.000224"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([])",
            "custom_output_dtype": "torch.float32",
            "status": "fail",
            "max_diff": 0.00022411346435546875,
            "avg_diff": 0.00022411346435546875
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": 0.00022411346435546875,
        "overall_avg_diff": 0.00022411346435546875
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    }
  ]
}