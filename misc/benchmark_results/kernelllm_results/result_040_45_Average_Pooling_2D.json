{
  "device_info": {
    "device_name": "NVIDIA GeForce RTX 4090",
    "device_id": 0,
    "device_str": "cuda:0",
    "compute_capability": [
      8,
      9
    ],
    "total_memory": 25386352640,
    "driver_version": "12.4",
    "backend": "triton"
  },
  "kernel_spec": {
    "description_file": "benchmark/level1/45_Average_Pooling_2D.py",
    "generator_file": "generators/kernelllm_generator.py",
    "warmup": 5,
    "iterations": 10,
    "max_diff_limit": 1e-05,
    "report_n": 10,
    "correctness_trials": 1,
    "seed": 42,
    "backend": "triton",
    "use_ncu": false
  },
  "baseline_time": 0.32356479167938235,
  "success_rate": 0.0,
  "avg_speedup": 0.0,
  "max_speedup": 0.0,
  "compilation_success_rate": 1.0,
  "correctness_success_rate": 0.0,
  "generations": [
    {
      "round": 0,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 147968\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 214\n    x1 = xindex // 214\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 768 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (256 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (257 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (258 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (512 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (513 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (514 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (2097152, 32768, 256, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 214, 214), (147968, 2304, 214, 1),\n            torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(147968)](arg0_1, buf0, 147968,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int'=None, padding: 'int'\n        =0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==2097152 at dim=0; expected size 64==64, stride 65536==32768 at dim=1",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 1,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 147968\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 214\n    x1 = xindex // 214\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 768 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (256 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (257 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (258 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (512 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (513 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (514 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (1048576, 16384, 256, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 214, 214), (295936, 4624, 214, 1),\n            torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(147968)](arg0_1, buf0, 147968,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int'=None, padding: 'int'\n        =0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==1048576 at dim=0; expected size 64==64, stride 65536==16384 at dim=1",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 2,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 1476096\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 213\n    x1 = xindex // 213 % 213\n    x2 = xindex // 45729\n    x3 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (256 + 3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (257 + 3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (258 + 3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (512 + 3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (513 + 3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (514 + 3 * x0 + 768 * x1 + 16384 * x2), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x3, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (2097152, 32768, 256, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 213, 213), (295936, 4576, 213, 1),\n            torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(1476096)](arg0_1, buf0, 1476096,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==2097152 at dim=0; expected size 64==64, stride 65536==32768 at dim=1",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 3,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 1024\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 8\n    x1 = xindex // 8\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 96 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 96 * x1), xmask, eviction_policy\n        ='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 96 * x1), xmask, eviction_policy\n        ='evict_last')\n    tmp5 = tl.load(in_ptr0 + (32 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (33 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (34 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (64 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (65 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (66 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (16777216, 65536, 256, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 8, 8), (4096, 64, 8, 1), torch.\n            float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(1024)](arg0_1, buf0, 1024,\n            XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding: 'int'\n        = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==16777216 at dim=0",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 4,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "```\nimport torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 147968\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 214\n    x1 = xindex // 214\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 768 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (256 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (257 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (258 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (512 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (513 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (514 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (2097152, 32768, 256, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 214, 214), (147968, 2312, 214, 1),\n            torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(147968)](arg0_1, buf0, 147968,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int'=None, padding: 'int'=0\n        ):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==2097152 at dim=0; expected size 64==64, stride 65536==32768 at dim=1",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 5,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 10469888\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 214\n    x1 = xindex // 214\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 768 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (256 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (257 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (258 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (512 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (513 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (514 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (16777216, 262144, 1024, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 214, 214), (295936, 4624, 214, 1),\n            torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(10469888)](arg0_1, buf0, 10469888,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding: 'int'\n        = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==16777216 at dim=0; expected size 64==64, stride 65536==262144 at dim=1; expected size 256==256, stride 256==1024 at dim=2",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 6,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 1024\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 8\n    x1 = xindex // 8\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 96 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 96 * x1), xmask, eviction_policy\n        ='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 96 * x1), xmask, eviction_policy\n        ='evict_last')\n    tmp5 = tl.load(in_ptr0 + (32 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (33 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (34 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (64 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (65 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (66 + 3 * x0 + 96 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (16777216, 65536, 256, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 8, 8), (4096, 64, 8, 1), torch.\n            float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(1024)](arg0_1, buf0, 1024,\n            XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int'=None, padding: 'int'\n        =0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==16777216 at dim=0",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 7,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 147968\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 214\n    x1 = xindex // 214\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 768 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (256 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (257 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (258 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (512 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (513 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (514 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (2097152, 32768, 256, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 214, 214), (147968, 2304, 214, 1),\n            torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(147968)](arg0_1, buf0, 147968,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==2097152 at dim=0; expected size 64==64, stride 65536==32768 at dim=1",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 8,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 147968\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 214\n    x1 = xindex // 214\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 768 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (256 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (257 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (258 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (512 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (513 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (514 + 3 * x0 + 768 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (16777216, 262144, 1024, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 214, 214), (147968, 2304, 214, 1),\n            torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(147968)](arg0_1, buf0, 147968,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int'=None, padding: 'int' = 0\n        ):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==16777216 at dim=0; expected size 64==64, stride 65536==262144 at dim=1; expected size 256==256, stride 256==1024 at dim=2",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 9,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": NaN,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_avg_pool2d_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.\n    constexpr):\n    xnumel = 1476096\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    xmask = xindex < xnumel\n    x0 = xindex % 215\n    x1 = xindex // 215\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (3 * x0 + 1024 * x1), xmask, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 3 * x0 + 1024 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 3 * x0 + 1024 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (256 + 3 * x0 + 1024 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (257 + 3 * x0 + 1024 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (258 + 3 * x0 + 1024 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (512 + 3 * x0 + 1024 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (513 + 3 * x0 + 1024 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (514 + 3 * x0 + 1024 * x1), xmask,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 + tmp0\n    tmp4 = tmp3 + tmp2\n    tmp6 = tmp5 + tmp4\n    tmp8 = tmp7 + tmp6\n    tmp10 = tmp9 + tmp8\n    tmp12 = tmp11 + tmp10\n    tmp14 = tmp13 + tmp12\n    tmp16 = tmp15 + tmp14\n    tmp17 = 0.1111111111111111\n    tmp18 = tmp16 * tmp17\n    tl.store(out_ptr0 + x2, tmp18, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 256, 256), (16777216, 262144, 1024, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 215, 215), (1476096, 23064, 215, \n            1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_avg_pool2d_0[grid(1476096)](arg0_1, buf0, 1476096,\n            XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs 2D Average Pooling.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0):\n        \"\"\"\n        Initializes the Average Pooling layer.\n\n        Args:\n            kernel_size (int): Size of the pooling window.\n            stride (int, optional): Stride of the pooling operation. Defaults to None (same as kernel_size).\n            padding (int, optional): Padding applied to the input tensor. Defaults to 0.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.avg_pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,\n            padding=padding)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "inf"
        ],
        "avg_differences": [
          "inf"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "status": "runtime_error",
            "error": "expected size 16==16, stride 4194304==16777216 at dim=0; expected size 64==64, stride 65536==262144 at dim=1; expected size 256==256, stride 256==1024 at dim=2",
            "error_type": "AssertionError"
          }
        ],
        "pass_count": 0,
        "total_trials": 1,
        "correctness_summary": "(0 / 1)",
        "overall_max_diff": Infinity,
        "overall_avg_diff": NaN
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    }
  ]
}