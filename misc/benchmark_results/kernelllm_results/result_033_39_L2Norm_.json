{
  "device_info": {
    "device_name": "NVIDIA GeForce RTX 4090",
    "device_id": 0,
    "device_str": "cuda:0",
    "compute_capability": [
      8,
      9
    ],
    "total_memory": 25386352640,
    "driver_version": "12.4",
    "backend": "triton"
  },
  "kernel_spec": {
    "description_file": "benchmark/level1/39_L2Norm_.py",
    "generator_file": "generators/kernelllm_generator.py",
    "warmup": 5,
    "iterations": 10,
    "max_diff_limit": 1e-05,
    "report_n": 10,
    "correctness_trials": 1,
    "seed": 42,
    "backend": "triton",
    "use_ncu": false
  },
  "baseline_time": 0.012383999675512314,
  "success_rate": 0.1,
  "avg_speedup": 0.5455314206824373,
  "max_speedup": 0.5455314206824373,
  "compilation_success_rate": 0.2,
  "correctness_success_rate": 0.1,
  "generations": [
    {
      "round": 0,
      "compiled": true,
      "correctness": true,
      "max_diff": 5.587935447692871e-09,
      "avg_diff": 3.4102454193885023e-10,
      "runtime": 0.022700800001621245,
      "speedup": 0.5455314206824373,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_div_linalg_vector_norm_0(in_ptr0, out_ptr1, xnumel,\n    rnumel, XBLOCK: tl.constexpr):\n    xnumel = 16\n    RBLOCK: tl.constexpr = 16384\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    xmask = xindex < xnumel\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r1 = rindex\n    x0 = xindex\n    tmp0 = tl.load(in_ptr0 + (r1 + 16384 * x0), xmask, other=0.0)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.where(xmask, tmp2, 0)\n    tmp5 = tl.sum(tmp4, 1)[:, None]\n    tmp6 = libdevice.sqrt(tmp5)\n    tmp7 = 1e-12\n    tmp8 = triton_helpers.maximum(tmp6, tmp7)\n    tmp9 = tmp0 / tmp8\n    tl.store(out_ptr1 + (r1 + 16384 * x0), tmp9, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf1 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_per_fused_div_linalg_vector_norm_0[grid(16)](arg0_1, buf1, \n            16, 16384, XBLOCK=1, num_warps=2, num_stages=1)\n        del arg0_1\n    return buf1,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [
          "0.000000"
        ],
        "avg_differences": [
          "0.000000"
        ],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 16384])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 16384])",
            "custom_output_dtype": "torch.float32",
            "status": "pass",
            "max_diff": 5.587935447692871e-09,
            "avg_diff": 3.4102454193885023e-10
          }
        ],
        "pass_count": 1,
        "total_trials": 1,
        "correctness_summary": "(1 / 1)",
        "overall_max_diff": 5.587935447692871e-09,
        "overall_avg_diff": 3.4102454193885023e-10
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 1,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_linalg_vector_norm_0(in_ptr0, out_ptr0, xnumel, rnumel,\n    XBLOCK: tl.constexpr):\n    RBLOCK: tl.constexpr = 16\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r2 = rindex\n    x0 = xindex % 16384\n    x1 = xindex // 16384\n    x3 = xindex\n    tmp0 = tl.load(in_ptr0 + (x0 + 16384 * r2 + 262144 * x1), None)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.sum(tmp2, 1)[:, None]\n    tl.store(out_ptr0 + x3, tmp4, None)\n\n\n@triton.jit\ndef triton_poi_fused_div_linalg_vector_norm_1(in_ptr0, in_ptr1, out_ptr0,\n    xnumel, XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 1024\n    x2 = xindex // 262144\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr1 + (x0 + 1024 * x2), None, eviction_policy=\n        'evict_last')\n    tmp2 = libdevice.sqrt(tmp1)\n    tmp3 = tmp0 / tmp2\n    tl.store(out_ptr0 + x3, tmp3, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 1, 16384), (16384, 262144, 1), torch\n            .float32)\n        get_raw_stream(0)\n        triton_per_fused_linalg_vector_norm_0[grid(262144)](arg0_1, buf0, \n            262144, 16, XBLOCK=32, num_warps=4, num_stages=1)\n        buf1 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        triton_poi_fused_div_linalg_vector_norm_1[grid(262144)](arg0_1,\n            buf0, buf1, 262144, XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n        del buf0\n    return buf1,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "runtime_error_name": "RuntimeError"
      },
      "compilation_error": null,
      "runtime_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "generation_error": null
    },
    {
      "round": 2,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_div_linalg_vector_norm_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x2 = xindex // 262144\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 262144 * x2), None, eviction_policy=\n        'evict_last')\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp6 = tl.load(in_ptr0 + (32768 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (49152 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 * tmp1\n    tmp4 = tmp3 * tmp3\n    tmp5 = tmp2 + tmp4\n    tmp7 = tmp6 * tmp6\n    tmp8 = tmp5 + tmp7\n    tmp10 = tmp9 * tmp9\n    tmp11 = tmp8 + tmp10\n    tmp12 = libdevice.sqrt(tmp11)\n    tmp13 = tmp0 / tmp12\n    tl.store(out_ptr0 + x3, tmp13, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_div_linalg_vector_norm_0[grid(262144)](arg0_1,\n            buf0, 262144, XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 3,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_div_linalg_vector_norm_0(in_ptr0, out_ptr1, xnumel,\n    rnumel, XBLOCK: tl.constexpr):\n    xnumel = 16\n    RBLOCK: tl.constexpr = 16384\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    xmask = xindex < xnumel\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r1 = rindex\n    x0 = xindex\n    tmp0 = tl.load(in_ptr0 + (r1 + 16384 * x0), xmask, other=0.0)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.where(xmask, tmp2, 0)\n    tmp5 = tl.sum(tmp4, 1)[:, None]\n    tmp6 = libdevice.sqrt(tmp5)\n    tmp7 = tmp0 / tmp6\n    tl.store(out_ptr1 + (r1 + 16384 * x0), tmp7, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf1 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_per_fused_div_linalg_vector_norm_0[grid(16)](arg0_1, buf1, \n            16, 16384, XBLOCK=1, num_warps=2, num_stages=1)\n        del arg0_1\n    return buf1,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 4,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_div_linalg_vector_norm_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x2 = xindex // 262144\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 262144 * x2), None, eviction_policy=\n        'evict_last')\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp6 = tl.load(in_ptr0 + (32768 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (49152 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp16 = tl.load(in_ptr0 + (65536 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 * tmp1\n    tmp4 = tmp3 * tmp3\n    tmp5 = tmp2 + tmp4\n    tmp7 = tmp6 * tmp6\n    tmp8 = tmp5 + tmp7\n    tmp10 = tmp9 * tmp9\n    tmp11 = tmp8 + tmp10\n    tmp12 = libdevice.sqrt(tmp11)\n    tmp13 = 1e-12\n    tmp14 = triton_helpers.maximum(tmp12, tmp13)\n    tmp15 = tmp0 / tmp14\n    tl.store(out_ptr0 + x3, tmp15, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_div_linalg_vector_norm_0[grid(262144)](arg0_1,\n            buf0, 262144, XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 5,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_linalg_vector_norm_0(in_ptr0, out_ptr0, xnumel, rnumel,\n    XBLOCK: tl.constexpr):\n    RBLOCK: tl.constexpr = 16\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r1 = rindex\n    x0 = xindex\n    tmp0 = tl.load(in_ptr0 + (r1 + 16 * x0), None)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.sum(tmp2, 1)[:, None]\n    tl.store(out_ptr0 + x0, tmp4, None)\n\n\n@triton.jit\ndef triton_poi_fused_div_linalg_vector_norm_1(in_ptr0, in_ptr1, out_ptr0,\n    xnumel, XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16\n    x2 = xindex // 16\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr1 + (x0 + 16 * x2), None, eviction_policy='evict_last'\n        )\n    tmp2 = libdevice.sqrt(tmp1)\n    tmp3 = tmp0 / tmp2\n    tl.store(out_ptr0 + x3, tmp3, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16384, 1), (1, 16384), torch.float32)\n        get_raw_stream(0)\n        triton_per_fused_linalg_vector_norm_0[grid(16384)](arg0_1, buf0, \n            16384, 16, XBLOCK=32, num_warps=4, num_stages=1)\n        buf1 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        triton_poi_fused_div_linalg_vector_norm_1[grid(262144)](arg0_1, buf0,\n            buf1, 262144, XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n        del buf0\n    return buf1,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 6,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_div_linalg_vector_norm_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 16384\n    x2 = xindex // 262144\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 262144 * x2), None, eviction_policy=\n        'evict_last')\n    tmp3 = tl.load(in_ptr0 + (16384 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp6 = tl.load(in_ptr0 + (32768 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (49152 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp16 = tl.load(in_ptr0 + (65536 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp19 = tl.load(in_ptr0 + (81920 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp22 = tl.load(in_ptr0 + (98304 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp29 = tl.load(in_ptr0 + (122880 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp32 = tl.load(in_ptr0 + (131072 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp35 = tl.load(in_ptr0 + (139264 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp38 = tl.load(in_ptr0 + (147456 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp45 = tl.load(in_ptr0 + (156800 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp48 = tl.load(in_ptr0 + (165888 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp51 = tl.load(in_ptr0 + (175616 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp58 = tl.load(in_ptr0 + (184320 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp61 = tl.load(in_ptr0 + (192768 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp64 = tl.load(in_ptr0 + (201216 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp71 = tl.load(in_ptr0 + (209728 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp74 = tl.load(in_ptr0 + (218880 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp77 = tl.load(in_ptr0 + (228864 + x0 + 262144 * x2), None,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 * tmp1\n    tmp4 = tmp3 * tmp3\n    tmp5 = tmp2 + tmp4\n    tmp7 = tmp6 * tmp6\n    tmp8 = tmp5 + tmp7\n    tmp10 = tmp9 * tmp9\n    tmp11 = tmp8 + tmp10\n    tmp12 = libdevice.sqrt(tmp11)\n    tmp13 = 1e-12\n    tmp14 = triton_helpers.maximum(tmp12, tmp13)\n    tmp15 = tmp0 / tmp14\n    tmp17 = tmp16 * tmp16\n    tmp18 = tmp17 + tmp3\n    tmp20 = tmp19 * tmp19\n    tmp21 = tmp18 + tmp20\n    tmp23 = tmp22 * tmp22\n    tmp24 = tmp21 + tmp23\n    tmp25 = libdevice.sqrt(tmp24)\n    tmp26 = triton_helpers.maximum(tmp25, tmp13)\n    tmp27 = tmp16 / tmp26\n    tmp28 = tmp15 - tmp27\n    tmp30 = tmp29 * tmp29\n    tmp31 = tmp30 + tmp3\n    tmp33 = tmp32 * tmp32\n    tmp34 = tmp31 + tmp33\n    tmp36 = tmp35 * tmp35\n    tmp37 = tmp34 + tmp36\n    tmp39 = tmp38 * tmp38\n    tmp40 = tmp37 + tmp39\n    tmp41 = libdevice.sqrt(tmp40)\n    tmp42 = triton_helpers.maximum(tmp41, tmp13)\n    tmp43 = tmp29 / tmp42\n    tmp44 = tmp28 - tmp43\n    tmp46 = tmp45 * tmp45\n    tmp47 = tmp46 + tmp3\n    tmp49 = tmp48 * tmp48\n    tmp50 = tmp47 + tmp49\n    tmp52 = tmp51 * tmp51\n    tmp53 = tmp50 + tmp52\n    tmp54 = libdevice.sqrt(tmp53)\n    tmp55 = triton_helpers.maximum(tmp54, tmp13)\n    tmp56 = tmp45 / tmp55\n    tmp57 = tmp44 - tmp56\n    tmp59 = tmp58 * tmp58\n    tmp60 = tmp59 + tmp3\n    tmp62 = tmp61 * tmp61\n    tmp63 = tmp60 + tmp62\n    tmp65 = tmp64 * tmp64\n    tmp66 = tmp63 + tmp65\n    tmp67 = libdevice.sqrt(tmp66)\n    tmp68 = triton_helpers.maximum(tmp67, tmp13)\n    tmp69 = tmp58 / tmp68\n    tmp70 = tmp57 - tmp69\n    tmp72 = tmp71 * tmp71\n    tmp73 = tmp72 + tmp3\n    tmp75 = tmp74 * tmp74\n    tmp76 = tmp73 + tmp75\n    tmp78 = tmp77 * tmp77\n    tmp79 = tmp76 + tmp78\n    tmp80 = libdevice.sqrt(tmp79)\n    tmp81 = triton_helpers.maximum(tmp80, tmp13)\n    tmp82 = tmp71 / tmp81\n    tmp83 = tmp70 - tmp82\n    tmp84 = tmp15 - tmp15\n    tmp85 = tmp3 + tmp3\n    tmp86 = tmp85 + tmp3\n    tmp87 = tmp86 + tmp3\n    tmp88 = tmp84 / tmp87\n    tmp89 = tmp18 - tmp18\n    tmp90 = tmp85 + tmp3\n    tmp91 = tmp90 + tmp3\n    tmp92 = tmp91 + tmp3\n    tmp93 = tmp89 / tmp92\n    tmp94 = tmp88 - tmp93\n    tmp95 = tmp24 - tmp24\n    tmp96 = tmp85 + tmp5\n    tmp97 = tmp96 + tmp3\n    tmp98 = tmp97 + tmp3\n    tmp99 = tmp95 / tmp98\n    tmp100 = tmp94 - tmp99\n    tmp101 = tmp30 - tmp30\n    tmp102 = tmp85 + tmp5\n    tmp103 = tmp102 + tmp3\n    tmp104 = tmp103 + tmp3\n    tmp105 = tmp101 / tmp104\n    tmp106 = tmp100 - tmp105\n    tmp107 = tmp40 - tmp40\n    tmp108 = tmp85 + tmp11\n    tmp109 = tmp108 + tmp3\n    tmp110 = tmp109 + tmp3\n    tmp111 = tmp107 / tmp110\n    tmp112 = tmp106 - tmp111\n    tmp113 = tmp46 - tmp46\n    tmp114 = tmp85 + tmp17\n    tmp115 = tmp114 + tmp3\n    tmp116 = tmp115 + tmp3\n    tmp117 = tmp113 / tmp116\n    tmp118 = tmp112 - tmp117\n    tmp119 = tmp53 - tmp53\n    tmp120 = tmp85 + tmp30\n    tmp121 = tmp120 + tmp3\n    tmp122 = tmp121 + tmp3\n    tmp123 = tmp119 / tmp122\n    tmp124 = tmp118 - tmp123\n    tmp125 = tmp66 - tmp66\n    tmp126 = tmp85 + tmp5\n    tmp127 = tmp126 + tmp3\n    tmp128 = tmp127 + tmp3\n    tmp129 = tmp125 / tmp128\n    tmp130 = tmp124 - tmp129\n    tmp131 = tmp72 - tmp72\n",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 7,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_linalg_vector_norm_0(in_ptr0, out_ptr0, xnumel, rnumel,\n    XBLOCK: tl.constexpr):\n    RBLOCK: tl.constexpr = 16384\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r1 = rindex\n    x0 = xindex\n    tmp0 = tl.load(in_ptr0 + (r1 + 16384 * x0), None)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.sum(tmp2, 1)[:, None]\n    tl.store(out_ptr0 + x0, tmp4, None)\n\n\n@triton.jit\ndef triton_poi_fused_div_linalg_vector_norm_1(in_ptr0, in_ptr1, out_ptr0,\n    xnumel, XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x2 = xindex\n    x1 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x2, None)\n    tmp1 = tl.load(in_ptr1 + x1, None, eviction_policy='evict_last')\n    tmp2 = libdevice.sqrt(tmp1)\n    tmp3 = tmp0 / tmp2\n    tl.store(out_ptr0 + x2, tmp3, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 1), (1, 16), torch.float32)\n        get_raw_stream(0)\n        triton_per_fused_linalg_vector_norm_0[grid(16)](arg0_1, buf0, 16, \n            16384, XBLOCK=1, num_warps=2, num_stages=1)\n        buf1 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        triton_poi_fused_div_linalg_vector_norm_1[grid(262144)](arg0_1, buf0,\n            buf1, 262144, XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n        del buf0\n    return buf1,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 8,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_poi_fused_div_linalg_vector_norm_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x3 = xindex\n    x0 = xindex % 1024\n    x2 = xindex // 16384\n    tmp0 = tl.load(in_ptr0 + x3, None)\n    tmp1 = tl.load(in_ptr0 + (x0 + 16384 * x2), None, eviction_policy=\n        'evict_last')\n    tmp3 = tl.load(in_ptr0 + (1024 + x0 + 16384 * x2), None, eviction_policy\n        ='evict_last')\n    tmp6 = tl.load(in_ptr0 + (2048 + x0 + 16384 * x2), None, eviction_policy\n        ='evict_last')\n    tmp9 = tl.load(in_ptr0 + (3072 + x0 + 16384 * x2), None, eviction_policy\n        ='evict_last')\n    tmp12 = tl.load(in_ptr0 + (4096 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (5120 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp18 = tl.load(in_ptr0 + (6144 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp21 = tl.load(in_ptr0 + (7168 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp24 = tl.load(in_ptr0 + (8192 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp27 = tl.load(in_ptr0 + (9216 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp30 = tl.load(in_ptr0 + (10240 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp33 = tl.load(in_ptr0 + (11264 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp36 = tl.load(in_ptr0 + (12288 + x0 + 16384 * x2), None,\n        eviction_policy='evict_last')\n    tmp2 = tmp1 * tmp1\n    tmp4 = tmp3 * tmp3\n    tmp5 = tmp2 + tmp4\n    tmp7 = tmp6 * tmp6\n    tmp8 = tmp5 + tmp7\n    tmp10 = tmp9 * tmp9\n    tmp11 = tmp8 + tmp10\n    tmp13 = tmp12 * tmp12\n    tmp14 = tmp11 + tmp13\n    tmp16 = tmp15 * tmp15\n    tmp17 = tmp14 + tmp16\n    tmp19 = tmp18 * tmp18\n    tmp20 = tmp17 + tmp19\n    tmp22 = tmp21 * tmp21\n    tmp23 = tmp20 + tmp22\n    tmp25 = tmp24 * tmp24\n    tmp26 = tmp23 + tmp25\n    tmp28 = tmp27 * tmp27\n    tmp29 = tmp26 + tmp28\n    tmp31 = tmp30 * tmp30\n    tmp32 = tmp29 + tmp31\n    tmp34 = tmp33 * tmp33\n    tmp35 = tmp32 + tmp34\n    tmp37 = tmp36 * tmp36\n    tmp38 = tmp35 + tmp37\n    tmp39 = libdevice.sqrt(tmp38)\n    tmp40 = tmp0 / tmp39\n    tl.store(out_ptr0 + x3, tmp40, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_poi_fused_div_linalg_vector_norm_0[grid(262144)](arg0_1,\n            buf0, 262144, XBLOCK=512, num_warps=8, num_stages=1)\n        del arg0_1\n    return buf0,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 9,
      "compiled": false,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nfrom torch._inductor.runtime.triton_helpers import libdevice\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n\n\n@triton.jit\ndef triton_per_fused_div_linalg_vector_norm_0(in_ptr0, out_ptr1, xnumel,\n    rnumel, XBLOCK: tl.constexpr):\n    xnumel = 16\n    RBLOCK: tl.constexpr = 16384\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    xmask = xindex < xnumel\n    rindex = tl.arange(0, RBLOCK)[None, :]\n    tl.full([XBLOCK, RBLOCK], True, tl.int1)\n    r1 = rindex\n    x0 = xindex\n    tmp0 = tl.load(in_ptr0 + (r1 + 16384 * x0), xmask, other=0.0)\n    tmp1 = tmp0 * tmp0\n    tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n    tmp4 = tl.where(xmask, tmp2, 0)\n    tmp5 = tl.sum(tmp4, 1)[:, None]\n    tmp6 = libdevice.sqrt(tmp5)\n    tmp7 = 1e-12\n    tmp8 = triton_helpers.maximum(tmp6, tmp7)\n    tmp9 = tmp0 / tmp8\n    tl.store(out_ptr1 + (r1 + 16384 * x0), tmp9, xmask)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 16384), (16384, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf1 = empty_strided_cuda((16, 16384), (16384, 1), torch.float32)\n        get_raw_stream(0)\n        triton_per_fused_div_linalg_vector_norm_0[grid(16)](arg0_1, buf1, \n            16, 16384, XBLOCK=1, num_warps=2, num_stages=1)\n        del arg0_1\n    return buf1,\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs L2 normalization.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the L2Norm layer.\n\n        Args:\n            dim (int): Dimension along which to normalize.\n        \"\"\"\n        super(ModelNew, self).__init__()\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "compilation_error_name": "RuntimeError"
      },
      "compilation_error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "runtime_error": null,
      "generation_error": null
    }
  ]
}