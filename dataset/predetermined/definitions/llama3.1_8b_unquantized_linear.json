{
  "name": "llama3.1_8b_unquantized_linear",
  "type": "gemm",
  "description": "A bias-add linear projection using torch.nn.functional.linear.",
  "axes": {
    "M": { "type": "var" },
    "K": { "type": "var" },
    "N": { "type": "var" }
  },
  "inputs": {
    "x": {
      "shape": ["M", "K"],
      "dtype": "bfloat16"
    },
    "weight": {
      "shape": ["N", "K"],
      "dtype": "bfloat16"
    },
    "bias": {
      "shape": ["N"],
      "dtype": "bfloat16"
    }
  },
  "outputs": {
    "out": {
      "shape": ["M", "N"],
      "dtype": "bfloat16"
    }
  },
  "reference": "import torch\n\ndef run(x, weight, bias):\n    out = torch.matmul(x, weight.T)\n    if bias is not None:\n        out = out + bias\n    return {\"out\": out}"
}
