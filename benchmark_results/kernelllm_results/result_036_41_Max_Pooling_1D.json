{
  "device_info": {
    "device_name": "NVIDIA GeForce RTX 4090",
    "device_id": 0,
    "device_str": "cuda:0",
    "compute_capability": [
      8,
      9
    ],
    "total_memory": 25386352640,
    "driver_version": "12.4",
    "backend": "triton"
  },
  "kernel_spec": {
    "description_file": "benchmark/level1/41_Max_Pooling_1D.py",
    "generator_file": "generators/kernelllm_generator.py",
    "warmup": 5,
    "iterations": 10,
    "max_diff_limit": 1e-05,
    "report_n": 10,
    "correctness_trials": 1,
    "seed": 42,
    "backend": "triton",
    "use_ncu": false
  },
  "baseline_time": 0.010236799716949463,
  "success_rate": 0.0,
  "avg_speedup": 0.0,
  "max_speedup": 0.0,
  "compilation_success_rate": 1.0,
  "correctness_success_rate": 0.0,
  "generations": [
    {
      "round": 0,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 128\n    x1 = xindex // 128\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (2 * x0 + 512 * x1), None, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 2 * x0 + 512 * x1), None, eviction_policy\n        ='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 2 * x0 + 512 * x1), None,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (3 + 2 * x0 + 512 * x1), None,\n        eviction_policy='evict_last')\n    tmp2 = triton_helpers.maximum(tmp1, tmp0)\n    tmp4 = triton_helpers.maximum(tmp3, tmp2)\n    tmp6 = triton_helpers.maximum(tmp5, tmp4)\n    tl.store(out_ptr0 + x2, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 64), (4096, 64, 64, 1), torch\n            .float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(65536)](arg0_1, buf0,\n            65536, XBLOCK=256, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 64), (4096, 64, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 64])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 64])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 64])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 1,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x1 = xindex // 64\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (2 * x0 + 256 * x1), None, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 2 * x0 + 256 * x1), None, eviction_policy\n        ='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (3 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (64 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (65 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (66 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (67 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (128 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp17 = tl.load(in_ptr0 + (129 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp19 = tl.load(in_ptr0 + (130 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp21 = tl.load(in_ptr0 + (131 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp23 = tl.load(in_ptr0 + (192 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp25 = tl.load(in_ptr0 + (193 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp27 = tl.load(in_ptr0 + (194 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp29 = tl.load(in_ptr0 + (195 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp2 = triton_helpers.maximum(tmp1, tmp0)\n    tmp4 = triton_helpers.maximum(tmp3, tmp2)\n    tmp6 = triton_helpers.maximum(tmp5, tmp4)\n    tmp8 = triton_helpers.maximum(tmp7, tmp6)\n    tmp10 = triton_helpers.maximum(tmp9, tmp8)\n    tmp12 = triton_helpers.maximum(tmp11, tmp10)\n    tmp14 = triton_helpers.maximum(tmp13, tmp12)\n    tmp16 = triton_helpers.maximum(tmp15, tmp14)\n    tmp18 = triton_helpers.maximum(tmp17, tmp16)\n    tmp20 = triton_helpers.maximum(tmp19, tmp18)\n    tmp22 = triton_helpers.maximum(tmp21, tmp20)\n    tmp24 = triton_helpers.maximum(tmp23, tmp22)\n    tmp26 = triton_helpers.maximum(tmp25, tmp24)\n    tmp28 = triton_helpers.maximum(tmp27, tmp26)\n    tmp30 = triton_helpers.maximum(tmp29, tmp28)\n    tl.store(out_ptr0 + x2, tmp30, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 32), (2048, 32, 32, 1), torch\n            .float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(32768)](arg0_1,\n            buf0, 32768, XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 32), (2048, 32, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 32])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 2,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x1 = xindex // 64\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (x0 + 128 * x1), None)\n    tmp1 = tl.load(in_ptr0 + (64 + x0 + 128 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (128 + x0 + 128 * x1), None)\n    tmp5 = tl.load(in_ptr0 + (192 + x0 + 128 * x1), None)\n    tmp2 = triton_helpers.maximum(tmp1, tmp0)\n    tmp4 = triton_helpers.maximum(tmp3, tmp2)\n    tmp6 = triton_helpers.maximum(tmp5, tmp4)\n    tl.store(out_ptr0 + x2, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 32), (2048, 32, 32, 1), torch.\n            float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(32768)](arg0_1, buf0,\n            32768, XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 32), (2048, 32, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 32])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 3,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x1 = xindex // 64\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (x0 + 128 * x1), None)\n    tmp1 = tl.load(in_ptr0 + (64 + x0 + 128 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (128 + x0 + 128 * x1), None)\n    tmp5 = tl.load(in_ptr0 + (192 + x0 + 128 * x1), None)\n    tmp2 = triton_helpers.maximum(tmp1, tmp0)\n    tmp4 = triton_helpers.maximum(tmp3, tmp2)\n    tmp6 = triton_helpers.maximum(tmp5, tmp4)\n    tl.store(out_ptr0 + x2, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 32), (2048, 32, 32, 1), torch\n            .float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(32768)](arg0_1, buf0,\n            32768, XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 32), (2048, 32, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 32])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 4,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x1 = xindex // 64\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (x0 + 128 * x1), None)\n    tmp1 = tl.load(in_ptr0 + (64 + x0 + 128 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (128 + x0 + 128 * x1), None)\n    tmp5 = tl.load(in_ptr0 + (192 + x0 + 128 * x1), None)\n    tmp2 = triton_helpers.maximum(tmp1, tmp0)\n    tmp4 = triton_helpers.maximum(tmp3, tmp2)\n    tmp6 = triton_helpers.maximum(tmp5, tmp4)\n    tl.store(out_ptr0 + x2, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 32), (2048, 32, 32, 1), torch\n            .float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(32768)](arg0_1, buf0,\n            32768, XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 32), (2048, 32, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 32])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 5,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x1 = xindex // 64\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (x0 + 128 * x1), None)\n    tmp1 = tl.load(in_ptr0 + (64 + x0 + 128 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (128 + x0 + 128 * x1), None)\n    tmp5 = tl.load(in_ptr0 + (192 + x0 + 128 * x1), None)\n    tmp2 = triton_helpers.maximum(tmp1, tmp0)\n    tmp4 = triton_helpers.maximum(tmp3, tmp2)\n    tmp6 = triton_helpers.maximum(tmp5, tmp4)\n    tl.store(out_ptr0 + x2, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 32), (2048, 32, 32, 1), torch.\n            float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(32768)](arg0_1, buf0,\n            32768, XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 32), (2048, 32, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 32])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 6,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "```\nimport torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x2 = xindex\n    tmp0 = tl.full([1], 0, tl.int64)\n    tmp1 = tmp0 >= tmp0\n    tmp2 = tl.full([1], 1, tl.int64)\n    tmp3 = tmp0 < tmp2\n    tmp4 = tmp1 & tmp3\n    tmp5 = -2 + 2 * x0\n    tmp6 = tmp5 >= tmp0\n    tmp7 = tl.full([1], 128, tl.int64)\n    tmp8 = tmp5 < tmp7\n    tmp9 = tmp6 & tmp8\n    tmp10 = tmp4 & tmp9\n    tmp11 = tl.load(in_ptr0 + (-2 + 2 * x2), tmp10, eviction_policy=\n        'evict_last', other=float('-inf'))\n    tmp12 = -1 + 2 * x0\n    tmp13 = tmp12 >= tmp0\n    tmp14 = tmp12 < tmp7\n    tmp15 = tmp13 & tmp14\n    tmp16 = tmp4 & tmp15\n    tmp17 = tl.load(in_ptr0 + (-1 + 2 * x2), tmp16, eviction_policy=\n        'evict_last', other=float('-inf'))\n    tmp18 = triton_helpers.maximum(tmp17, tmp11)\n    tmp19 = 2 * x0\n    tmp20 = tmp19 >= tmp0\n    tmp21 = tmp19 < tmp7\n    tmp22 = tmp20 & tmp21\n    tmp23 = tmp4 & tmp22\n    tmp24 = tl.load(in_ptr0 + 2 * x2, tmp23, eviction_policy='evict_last',\n        other=float('-inf'))\n    tmp25 = triton_helpers.maximum(tmp24, tmp18)\n    tmp26 = 1 + 2 * x0\n    tmp27 = tmp26 >= tmp0\n    tmp28 = tmp26 < tmp7\n    tmp29 = tmp27 & tmp28\n    tmp30 = tmp4 & tmp29\n    tmp31 = tl.load(in_ptr0 + (1 + 2 * x2), tmp30, eviction_policy=\n        'evict_last', other=float('-inf'))\n    tmp32 = triton_helpers.maximum(tmp31, tmp25)\n    tl.store(out_ptr0 + x2, tmp32, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 64), (4096, 64, 64, 1), torch.\n            float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(65536)](arg0_1, buf0,\n            65536, XBLOCK=256, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 64), (4096, 64, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int'=None, padding: 'int'\n        =0, dilation: 'int'=1, return_indices: 'bool'=False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 64])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 64])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 64])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 7,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x1 = xindex // 64\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (x0 + 128 * x1), None)\n    tmp1 = tl.load(in_ptr0 + (64 + x0 + 128 * x1), None)\n    tmp3 = tl.load(in_ptr0 + (128 + x0 + 128 * x1), None)\n    tmp5 = tl.load(in_ptr0 + (192 + x0 + 128 * x1), None)\n    tmp2 = triton_helpers.maximum(tmp1, tmp0)\n    tmp4 = triton_helpers.maximum(tmp3, tmp2)\n    tmp6 = triton_helpers.maximum(tmp5, tmp4)\n    tl.store(out_ptr0 + x2, tmp6, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 32), (2048, 32, 32, 1), torch.\n            float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(32768)](arg0_1, buf0,\n            32768, XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 32), (2048, 32, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding: 'int'\n        = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 32])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 8,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x2 = xindex\n    tmp0 = tl.full([1], 0, tl.int64)\n    tmp1 = tmp0 >= tmp0\n    tmp2 = tl.full([1], 1, tl.int64)\n    tmp3 = tmp0 < tmp2\n    tmp4 = tmp1 & tmp3\n    tmp5 = -2 + 3 * x0\n    tmp6 = tmp5 >= tmp0\n    tmp7 = tl.full([1], 128, tl.int64)\n    tmp8 = tmp5 < tmp7\n    tmp9 = tmp6 & tmp8\n    tmp10 = tmp4 & tmp9\n    tmp11 = tl.load(in_ptr0 + (-2 + 3 * x2), tmp10, eviction_policy=\n        'evict_last', other=float('-inf'))\n    tmp12 = -1 + 3 * x0\n    tmp13 = tmp12 >= tmp0\n    tmp14 = tmp12 < tmp7\n    tmp15 = tmp13 & tmp14\n    tmp16 = tmp4 & tmp15\n    tmp17 = tl.load(in_ptr0 + (-1 + 3 * x2), tmp16, eviction_policy=\n        'evict_last', other=float('-inf'))\n    tmp18 = triton_helpers.maximum(tmp17, tmp11)\n    tmp19 = 3 * x0\n    tmp20 = tmp19 >= tmp0\n    tmp21 = tmp19 < tmp7\n    tmp22 = tmp20 & tmp21\n    tmp23 = tmp4 & tmp22\n    tmp24 = tl.load(in_ptr0 + 3 * x2, tmp23, eviction_policy='evict_last',\n        other=float('-inf'))\n    tmp25 = triton_helpers.maximum(tmp24, tmp18)\n    tmp26 = 1 + 3 * x0\n    tmp27 = tmp26 >= tmp0\n    tmp28 = tmp26 < tmp7\n    tmp29 = tmp27 & tmp28\n    tmp30 = tmp4 & tmp29\n    tmp31 = tl.load(in_ptr0 + (1 + 3 * x2), tmp30, eviction_policy=\n        'evict_last', other=float('-inf'))\n    tmp32 = triton_helpers.maximum(tmp31, tmp25)\n    tl.store(out_ptr0 + x2, tmp32, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 32), (2048, 32, 32, 1), torch.\n            float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(32768)](arg0_1, buf0,\n            32768, XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 32), (2048, 32, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 32])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    },
    {
      "round": 9,
      "compiled": true,
      "correctness": false,
      "max_diff": Infinity,
      "avg_diff": Infinity,
      "runtime": null,
      "speedup": null,
      "generated_code": "import torch\nimport triton\nimport triton.language as tl\nfrom torch._inductor.runtime.triton_heuristics import grid\nfrom torch._C import _cuda_getCurrentRawStream as get_raw_stream\nfrom torch._inductor.runtime import triton_helpers\nimport torch.nn as nn\nassert_size_stride = torch._C._dynamo.guards.assert_size_stride\nempty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\nreinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor\n\n\n@triton.jit\ndef triton_poi_fused_max_pool2d_with_indices_0(in_ptr0, out_ptr0, xnumel,\n    XBLOCK: tl.constexpr):\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n    tl.full([XBLOCK], True, tl.int1)\n    x0 = xindex % 64\n    x1 = xindex // 64\n    x2 = xindex\n    tmp0 = tl.load(in_ptr0 + (2 * x0 + 256 * x1), None, eviction_policy=\n        'evict_last')\n    tmp1 = tl.load(in_ptr0 + (1 + 2 * x0 + 256 * x1), None, eviction_policy\n        ='evict_last')\n    tmp3 = tl.load(in_ptr0 + (2 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp5 = tl.load(in_ptr0 + (3 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp7 = tl.load(in_ptr0 + (64 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp9 = tl.load(in_ptr0 + (65 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp11 = tl.load(in_ptr0 + (66 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp13 = tl.load(in_ptr0 + (67 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp15 = tl.load(in_ptr0 + (128 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp17 = tl.load(in_ptr0 + (129 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp19 = tl.load(in_ptr0 + (130 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp21 = tl.load(in_ptr0 + (131 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp23 = tl.load(in_ptr0 + (192 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp25 = tl.load(in_ptr0 + (193 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp27 = tl.load(in_ptr0 + (194 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp29 = tl.load(in_ptr0 + (195 + 2 * x0 + 256 * x1), None,\n        eviction_policy='evict_last')\n    tmp2 = triton_helpers.maximum(tmp1, tmp0)\n    tmp4 = triton_helpers.maximum(tmp3, tmp2)\n    tmp6 = triton_helpers.maximum(tmp5, tmp4)\n    tmp8 = triton_helpers.maximum(tmp7, tmp6)\n    tmp10 = triton_helpers.maximum(tmp9, tmp8)\n    tmp12 = triton_helpers.maximum(tmp11, tmp10)\n    tmp14 = triton_helpers.maximum(tmp13, tmp12)\n    tmp16 = triton_helpers.maximum(tmp15, tmp14)\n    tmp18 = triton_helpers.maximum(tmp17, tmp16)\n    tmp20 = triton_helpers.maximum(tmp19, tmp18)\n    tmp22 = triton_helpers.maximum(tmp21, tmp20)\n    tmp24 = triton_helpers.maximum(tmp23, tmp22)\n    tmp26 = triton_helpers.maximum(tmp25, tmp24)\n    tmp28 = triton_helpers.maximum(tmp27, tmp26)\n    tmp30 = triton_helpers.maximum(tmp29, tmp28)\n    tl.store(out_ptr0 + x2, tmp30, None)\n\n\ndef call(args):\n    arg0_1, = args\n    args.clear()\n    assert_size_stride(arg0_1, (16, 64, 128), (8192, 128, 1))\n    with torch.cuda._DeviceGuard(0):\n        torch.cuda.set_device(0)\n        buf0 = empty_strided_cuda((16, 64, 1, 32), (2048, 32, 32, 1), torch\n            .float32)\n        get_raw_stream(0)\n        triton_poi_fused_max_pool2d_with_indices_0[grid(32768)](arg0_1,\n            buf0, 32768, XBLOCK=128, num_warps=4, num_stages=1)\n        del arg0_1\n    return reinterpret_tensor(buf0, (16, 64, 32), (2048, 32, 1), 0),\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs Max Pooling 1D.\n    \"\"\"\n\n    def __init__(self, kernel_size: 'int', stride: 'int' = None, padding:\n        'int' = 0, dilation: 'int' = 1, return_indices: 'bool' = False):\n        \"\"\"\n        Initializes the Max Pooling 1D layer.\n\n        Args:\n            kernel_size (int): Size of the window to take a max over.\n            stride (int, optional): Stride of the window. Defaults to None (same as kernel_size).\n            padding (int, optional): Implicit zero padding to be added on both sides. Defaults to 0.\n            dilation (int, optional): Spacing between kernel elements. Defaults to 1.\n            return_indices (bool, optional): Whether to return the indices of the maximum values. Defaults to False.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride,\n            padding=padding, dilation=dilation, return_indices=return_indices)\n\n    def forward(self, input_0):\n        arg0_1 = input_0\n        output = call([arg0_1])\n        return output[0]\n```",
      "ncu_results": {},
      "metadata": {
        "correctness_trials_attempted": 1,
        "max_differences": [],
        "avg_differences": [],
        "trial_results": [
          {
            "trial": 0,
            "seed": 1608637542,
            "original_output_type": "<class 'torch.Tensor'>",
            "custom_output_type": "<class 'torch.Tensor'>",
            "original_output_shape": "torch.Size([16, 64, 62])",
            "original_output_dtype": "torch.float32",
            "custom_output_shape": "torch.Size([16, 64, 32])",
            "custom_output_dtype": "torch.float32",
            "correctness_error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])",
            "status": "shape_mismatch",
            "error": "Output shape mismatch: Expected torch.Size([16, 64, 62]), got torch.Size([16, 64, 32])"
          }
        ]
      },
      "compilation_error": null,
      "runtime_error": null,
      "generation_error": null
    }
  ]
}